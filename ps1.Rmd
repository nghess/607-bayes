---
title: "Problem Set 1"
author: "Nate Gonzales-Hess"
date: "2025-04-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = "center")
library(tidyverse)  # Load any packages you need here
```

## Problem 1: Globe Tossing Posterior Distribution

*Suppose the globe tossing experiment turned out to be 3 water and 11 land. Construct the posterior distribution.*

```{r problem1}
# Function to compute posterior for a given sample and range of possible proportions.
compute_posterior = function(sample, possible){
  
  W = sum(sample == "W")
  L = sum(sample == "L")
  
  prior = rep(1, length(possible)) # 2. Calculate likelihood and prior
  likelihood = sapply(possible, function(x) dbinom(x = W, size = W+L, prob = x))
  post = (prior * likelihood) / sum(prior * likelihood)  # 3. Calculate posterior probability
  
  return(post)
}

# Sample with 3 water and 13 land:
sample = c("W","W","W","L","L","L","L","L","L","L","L","L","L","L","L","L")
# 1. Create a grid of possible proportion values
possible = seq(0,1,length.out=50)
# Compute posteriors
posterior = compute_posterior(sample, possible)

# 4. Create a plot of the posterior distribution
barplot(posterior, names.arg = round(possible,2),
        main = "Posterior probabilities for possible proportions of water to land",
        xlab = "Proportion Water",
        ylab = "Density")
```
Starting from a flat prior, the posterior probability peaks around .20 (proportion of "W" to total) which makes sense, given that we observed 3 "W"s in 16 tosses and 3/16 = .1875. *This being a distribution, we aren't concerned with a particular value along the x-axis, but with the entire distribution. Still the distribution reflects the values in the sample pretty closely.

## Problem 2: Posterior Predictive Distribution

*Using the posterior distribution from Problem 1, compute the posterior predictive distribution for the next 5 tosses of the globe.*

```{r problem2}
n_tosses = 5  # Number of steps in our simulation
sim_iters = 1000  # Number of times to run the simulated globe toss
predicted_counts = rep(0, n_tosses+1)  # Empty vector to store predicted "W" counts (0-5 possible "W" observations)

# 1. Sample from your posterior distribution
post_samples <- sample(possible, size=sim_iters, prob=posterior, replace=TRUE )

# 2. Use these samples to simulate new tosses
sim_globe = function( p=0.7 , N=5 ){
  sample(
    x = c("W", "L"),  # possible values
    size = N,         # how many draws
    prob = c(p, 1-p), # probability of each possibility
    replace = TRUE    # the same value can be drawn multiple times
  )
}

# Run simulation
for (i in 1:sim_iters){
  p = post_samples[i]
  tosses = sim_globe(p, n_tosses)
  water_count = sum(tosses == "W")
  predicted_counts[water_count+1] = predicted_counts[water_count+1] + 1
}

# 3. Create a visualization of the predictions
barplot(predicted_counts, names.arg = seq(0,5),
        main = "Posterior Predictive Distribution (5 new tosses)",
        xlab = "Number of \"W\"",
        ylab = "Count")
```

Using the posterior distribution to fuel 5 simulated tosses yielded a posterior predictive distribution that agreed well with the posterior probabilities. In 1000 simulated 5-toss runs, we saw 347 runs that yielded zero "W"s, 362 runs that yielded one "W", 198 runs that yielded two "W"s, 69 runs that yielded three "W"s, 22 runs that yielded four "W"s and 2 runs that gave five "W"s. --These counts aren't important on their own, but they give an approximate probability for each of the outcomes, and these probabilities fit well with the posterior probability, generated from a sample containing 3 "W"s and 13 "L"s. --In terms of generating data, this approach would yield samples pretty similar to the 3 "W" 13 "L" sample we started from.

## Session Information

```{r session-info}
# This will help with debugging and reproducibility
sessionInfo()
```



```{r}
library(rethinking)

f <- alist(
    y ~ dnorm( mu , sigma ),
    mu ~ dnorm( 0 , 10 ),
    sigma ~ dexp( 1 )
)

fit <- quap( 
    f , 
    data=list(y=c(-1,1)) , 
    start=list(mu=0,sigma=1)
)
```